# sp_api_service.py - Prime+å‡ºå“è€…æƒ…å ±çµ±åˆãƒ•ãƒ«ã‚³ãƒ¼ãƒ‰ç‰ˆ
from sp_api.api import CatalogItems
from sp_api.api import Products as ProductPricing
from sp_api.base import Marketplaces, SellingApiException
import time
import os
from dotenv import load_dotenv
import re
import pandas as pd
import json
import unicodedata
from pathlib import Path
import streamlit as st
import openai
import google.generativeai as genai
import jellyfish

# .envèª­ã¿è¾¼ã¿ï¼ˆshopeeç›´ä¸‹ã®.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
env_path = parent_dir / '.env'
load_dotenv(env_path)

# å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼ID ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆï¼ˆå¿…è¦ã«å¿œã˜ã¦è¿½åŠ ï¼‰
WHITELIST_OFFICIAL_IDS = {
    'A1234567890ABCDE',  # ä¾‹ï¼šãƒ•ã‚¡ãƒ³ã‚±ãƒ«å…¬å¼ï¼ˆå®Ÿéš›ã®IDã«è¦å¤‰æ›´ï¼‰
    'B0987654321XYZ12',  # ä¾‹ï¼šè³‡ç”Ÿå ‚å…¬å¼ï¼ˆå®Ÿéš›ã®IDã«è¦å¤‰æ›´ï¼‰
    # TODO: å®Ÿéš›ã®å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼ã‚»ãƒ©ãƒ¼IDã‚’è¿½åŠ 
}

def similar(a, b, threshold=0.85):  # 0.9 â†’ 0.85 ã«å¤‰æ›´
    """Jaro-Winkleré¡ä¼¼åº¦ã«ã‚ˆã‚‹æ–‡å­—åˆ—æ¯”è¼ƒï¼ˆæ—¥æœ¬èªå¯¾å¿œèª¿æ•´ç‰ˆï¼‰"""
    if not a or not b:
        return False
    return jellyfish.jaro_winkler_similarity(a.lower().strip(), b.lower().strip()) > threshold

def is_official_seller(seller_id, seller_name, brand_name):
    """
    å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼åˆ¤å®šï¼ˆ3ã¤ã®æ–¹æ³•ï¼‰- æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³èª¿æ•´ç‰ˆ
    """
    if not seller_name:
        return False
    # æ–¹æ³•1: ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆIDåˆ¤å®š
    if seller_id in WHITELIST_OFFICIAL_IDS:
        print(f"     âœ… å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼åˆ¤å®š: ãƒ›ãƒ¯ã‚¤ãƒˆãƒªã‚¹ãƒˆID ({seller_id})")
        return True
    # æ–¹æ³•2: Jaro-Winkleré¡ä¼¼åº¦åˆ¤å®šï¼ˆé–¾å€¤èª¿æ•´ï¼‰
    if brand_name and similar(brand_name, seller_name, 0.85):  # é–¾å€¤ã‚’0.85ã«èª¿æ•´
        similarity_score = jellyfish.jaro_winkler_similarity(brand_name.lower(), seller_name.lower())
        print(f"     âœ… å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼åˆ¤å®š: é¡ä¼¼åº¦{similarity_score:.3f} ({brand_name} â‰ˆ {seller_name})")
        return True
    # æ–¹æ³•3: æ­£è¦è¡¨ç¾åˆ¤å®šï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³æ‹¡å¼µï¼‰
    official_patterns = [
        r'(official|å…¬å¼|ç›´å–¶|_jp)$',     # æœ«å°¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        r'(official|å…¬å¼|ç›´å–¶)',          # ä»»æ„ä½ç½®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ–°è¦è¿½åŠ ï¼‰
        r'^\w+å…¬å¼',                      # å…ˆé ­ãƒ–ãƒ©ãƒ³ãƒ‰å+å…¬å¼ãƒ‘ã‚¿ãƒ¼ãƒ³
    ]
    for pattern in official_patterns:
        if re.search(pattern, seller_name.lower()):
            print(f"     âœ… å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼åˆ¤å®š: æ­£è¦è¡¨ç¾ãƒãƒƒãƒ ({seller_name}) - ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}")
            return True
    print(f"     âŒ å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼åˆ¤å®š: éè©²å½“ ({seller_name})")
    return False

def get_japanese_name_from_gpt4o(clean_title):
    """GPT-4oã«ã‚ˆã‚‹é«˜å“è³ªæ—¥æœ¬èªåŒ–ï¼ˆæ—¢å­˜llm_service.pyçµ±åˆï¼‰"""
    try:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            return None, "OpenAI API Key not found"
            
        client = openai.OpenAI(api_key=api_key)
        # å˜èªåˆ†å‰²ã—ã‚„ã™ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ”¹å–„
        prompt = f"æ¬¡ã®è‹±èªã®å•†å“åã‚’ã€æ—¥æœ¬ã®ECã‚µã‚¤ãƒˆã§é€šã˜ã‚‹è‡ªç„¶ãªæ—¥æœ¬èªã®å•†å“åã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚å„å˜èªã¯åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã§åŒºåˆ‡ã‚Šã€ãƒ–ãƒ©ãƒ³ãƒ‰ã‚„å®¹é‡ã‚‚æ—¥æœ¬èªã§è¡¨è¨˜ã—ã€èª¬æ˜ã‚„ä½™è¨ˆãªèªå¥ã¯ä¸è¦ï¼š\n\n{clean_title}"
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=64,
            temperature=0.3,
        )
        
        japanese_name = response.choices[0].message.content.strip()
        print(f"   ğŸ¤– GPT-4oæ—¥æœ¬èªåŒ–: {clean_title} â†’ {japanese_name}")
        return japanese_name, "GPT-4o"
        
    except Exception as e:
        print(f"   âŒ GPT-4oæ—¥æœ¬èªåŒ–å¤±æ•—: {e}")
        return None, f"GPT-4o Error: {e}"

def get_japanese_name_from_gemini(clean_title):
    """Geminiã«ã‚ˆã‚‹æ—¥æœ¬èªåŒ–ï¼ˆæ—¢å­˜llm_service.pyçµ±åˆãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç”¨ï¼‰"""
    try:
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            return None, "Gemini API Key not found"
            
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-pro-latest')
        prompt = f"æ¬¡ã®è‹±èªã®å•†å“åã‚’ã€æ—¥æœ¬èªã®å•†å“åã«è‡ªç„¶ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚ãƒ–ãƒ©ãƒ³ãƒ‰ã‚„å®¹é‡ã‚‚è‡ªç„¶ãªæ—¥æœ¬èªã§ã€‚ä½™è¨ˆãªèª¬æ˜ä¸è¦ï¼š\n\n{clean_title}"
        
        response = model.generate_content(prompt)
        japanese_name = response.text.strip()
        print(f"   ğŸ”® Geminiæ—¥æœ¬èªåŒ–: {clean_title} â†’ {japanese_name}")
        return japanese_name, "Gemini"
        
    except Exception as e:
        print(f"   âŒ Geminiæ—¥æœ¬èªåŒ–å¤±æ•—: {e}")
        return None, f"Gemini Error: {e}"

def get_japanese_name_hybrid(clean_title):
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ—¥æœ¬èªåŒ–ï¼ˆæ—¢å­˜llm_service.pyå®Œå…¨çµ±åˆï¼‰"""
    print(f"   ğŸš€ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ—¥æœ¬èªåŒ–é–‹å§‹: {clean_title}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: GPT-4oã‚’è©¦è¡Œï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰
    jp_name, source = get_japanese_name_from_gpt4o(clean_title)
    
    if jp_name and not jp_name.isspace() and "å¤‰æ›ä¸å¯" not in jp_name:
        print(f"   âœ… GPT-4oæˆåŠŸ: {jp_name}")
        return jp_name, source
    else:
        print(f"   âš ï¸ GPT-4oå¤±æ•—ã€Geminiã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ...")
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: Geminiã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæœ€æ–°å•†å“å¯¾å¿œï¼‰
    jp_name, source = get_japanese_name_from_gemini(clean_title)
    
    if jp_name and not jp_name.isspace() and "å¤‰æ›ä¸å¯" not in jp_name:
        print(f"   âœ… Geminiãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆåŠŸ: {jp_name}")
        return jp_name, source
    else:
        print(f"   âŒ ä¸¡æ–¹å¤±æ•—ã€å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨: {clean_title}")
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: ä¸¡æ–¹å¤±æ•—æ™‚ã¯å…ƒã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¿”ã™
    return clean_title, "Original"

def get_credentials():
    """SP-APIèªè¨¼æƒ…å ±å–å¾—ï¼ˆ2023å¹´10æœˆä»¥é™LWAå°‚ç”¨ç‰ˆï¼‰"""
    # LWAèªè¨¼æƒ…å ±ã®ã¿å–å¾—ï¼ˆAWSèªè¨¼ã¯2023å¹´10æœˆä»¥é™ä¸è¦ï¼‰
    lwa_app_id = os.getenv("SP_API_LWA_APP_ID")
    lwa_client_secret = os.getenv("SP_API_LWA_CLIENT_SECRET")
    refresh_token = os.getenv("SP_API_LWA_REFRESH_TOKEN")
    
    print(f"ğŸ“ .envãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {env_path}")
    print(f"SP_API_LWA_APP_ID: {'ã‚ã‚Š' if lwa_app_id else 'ãªã—'}")
    print(f"SP_API_LWA_CLIENT_SECRET: {'ã‚ã‚Š' if lwa_client_secret else 'ãªã—'}")
    print(f"SP_API_LWA_REFRESH_TOKEN: {'ã‚ã‚Š' if refresh_token else 'ãªã—'}")
    print(f"ğŸ†• 2023å¹´10æœˆä»¥é™: AWSèªè¨¼æƒ…å ±ã¯ä¸è¦ï¼ˆLWAã®ã¿ï¼‰")
    print(f"OPENAI_API_KEY: {'ã‚ã‚Š' if os.getenv('OPENAI_API_KEY') else 'ãªã—'}")
    print(f"GEMINI_API_KEY: {'ã‚ã‚Š' if os.getenv('GEMINI_API_KEY') else 'ãªã—'}")
    
    if not all([lwa_app_id, lwa_client_secret, refresh_token]):
        missing = []
        if not lwa_app_id: missing.append("SP_API_LWA_APP_ID")
        if not lwa_client_secret: missing.append("SP_API_LWA_CLIENT_SECRET")
        if not refresh_token: missing.append("SP_API_LWA_REFRESH_TOKEN")
        
        print(f"âŒ LWAèªè¨¼æƒ…å ±ãŒä¸è¶³: {', '.join(missing)}")
        return None
    
    # LWAèªè¨¼ã®ã¿ã§ååˆ†ï¼ˆAWSç½²åã¯2023å¹´10æœˆä»¥é™ç„¡è¦–ã•ã‚Œã‚‹ï¼‰
    credentials = {
        "lwa_app_id": lwa_app_id,
        "lwa_client_secret": lwa_client_secret,
        "refresh_token": refresh_token,
        "use_aws_auth": False  # æ˜ç¤ºçš„ã«AWSèªè¨¼ã‚’ç„¡åŠ¹åŒ–
    }
    
    print("âœ… SP-APIèªè¨¼æƒ…å ±å–å¾—æˆåŠŸï¼ˆLWAã®ã¿ï¼‰")
    return credentials

def load_brand_dict():
    """é«˜å“è³ªãƒ–ãƒ©ãƒ³ãƒ‰è¾æ›¸ã®èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜brands.jsonæ´»ç”¨ï¼‰"""
    try:
        # æ­£ã—ã„ãƒ‘ã‚¹: /workspaces/shopee/data/brands.json
        brands_file_path = current_dir.parent / 'data' / 'brands.json'
        
        if brands_file_path.exists():
            with open(brands_file_path, 'r', encoding='utf-8') as f:
                existing_brands = json.load(f)
            
            print(f"ğŸ“š æ—¢å­˜brands.jsonã‹ã‚‰èª­ã¿è¾¼ã¿: {len(existing_brands)}ãƒ–ãƒ©ãƒ³ãƒ‰")
            print(f"ğŸ“ èª­ã¿è¾¼ã¿ãƒ‘ã‚¹: {brands_file_path}")
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ãƒ‡ãƒãƒƒã‚°
            if existing_brands:
                first_key = list(existing_brands.keys())[0]
                first_value = existing_brands[first_key]
                print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚µãƒ³ãƒ—ãƒ«:")
                print(f"   ã‚­ãƒ¼ä¾‹: {first_key}")
                print(f"   å€¤ä¾‹: {first_value} (å‹: {type(first_value)})")
                
                # å€¤ã®å‹åˆ†æ
                value_types = {}
                for key, value in list(existing_brands.items())[:5]:  # æœ€åˆã®5ä»¶ã‚’åˆ†æ
                    value_type = type(value).__name__
                    if value_type not in value_types:
                        value_types[value_type] = []
                    value_types[value_type].append(f"{key}: {value}")
                
                print(f"   å€¤ã®å‹åˆ†å¸ƒ: {list(value_types.keys())}")
                for vtype, examples in value_types.items():
                    print(f"     {vtype}: {examples[0]}")
            
            return existing_brands
        else:
            print(f"âš ï¸ brands.jsonãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {brands_file_path}")
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
    except Exception as e:
        print(f"âš ï¸ brands.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¾æ›¸ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        import traceback
        print("è©³ç´°ã‚¨ãƒ©ãƒ¼:")
        traceback.print_exc()
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ–ãƒ©ãƒ³ãƒ‰è¾æ›¸ï¼ˆbrands.jsonãŒãªã„å ´åˆï¼‰
    fallback_brands = {
        # åŒ–ç²§å“ãƒ»ã‚¹ã‚­ãƒ³ã‚±ã‚¢
        "FANCL": ["ãƒ•ã‚¡ãƒ³ã‚±ãƒ«", "fancl"],
        "ORBIS": ["ã‚ªãƒ«ãƒ“ã‚¹", "orbis"],
        "SK-II": ["ã‚¨ã‚¹ã‚±ãƒ¼ãƒ„ãƒ¼", "SK2", "SK-2"],
        "SHISEIDO": ["è³‡ç”Ÿå ‚", "shiseido"],
        "KANEBO": ["ã‚«ãƒãƒœã‚¦", "kanebo"],
        "KOSE": ["ã‚³ãƒ¼ã‚»ãƒ¼", "kose"],
        "POLA": ["ãƒãƒ¼ãƒ©", "pola"],
        "ALBION": ["ã‚¢ãƒ«ãƒ“ã‚ªãƒ³", "albion"],
        "HABA": ["ãƒãƒ¼ãƒãƒ¼", "haba"],
        "DHC": ["ãƒ‡ã‚£ãƒ¼ã‚¨ã‚¤ãƒã‚·ãƒ¼", "dhc"],
        
        # ãƒ˜ã‚¢ã‚±ã‚¢
        "MILBON": ["ãƒŸãƒ«ãƒœãƒ³", "milbon"],
        "LEBEL": ["ãƒ«ãƒ™ãƒ«", "lebel"],
        "YOLU": ["ãƒ¨ãƒ«", "yolu"],
        "TSUBAKI": ["æ¤¿", "tsubaki"],
        "LISSAGE": ["ãƒªã‚µãƒ¼ã‚¸", "lissage"],
        "KERASTASE": ["ã‚±ãƒ©ã‚¹ã‚¿ãƒ¼ã‚¼", "kerastase"],
        
        # å®¶é›»ãƒ»ç¾å®¹æ©Ÿå™¨
        "PANASONIC": ["ãƒ‘ãƒŠã‚½ãƒ‹ãƒƒã‚¯", "panasonic"],
        "PHILIPS": ["ãƒ•ã‚£ãƒªãƒƒãƒ—ã‚¹", "philips"],
        "KOIZUMI": ["ã‚³ã‚¤ã‚ºãƒŸ", "koizumi"],
        "HITACHI": ["æ—¥ç«‹", "hitachi"],
        
        # å¥åº·é£Ÿå“ãƒ»ã‚µãƒ—ãƒª
        "SUNTORY": ["ã‚µãƒ³ãƒˆãƒªãƒ¼", "suntory"],
        "ASAHI": ["ã‚¢ã‚µãƒ’", "asahi"],
        "MEIJI": ["æ˜æ²»", "meiji"],
        "MORINAGA": ["æ£®æ°¸", "morinaga"],
    }
    
    print(f"ğŸ“š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¾æ›¸ä½¿ç”¨: {len(fallback_brands)}ãƒ–ãƒ©ãƒ³ãƒ‰")
    return fallback_brands

def advanced_product_name_cleansing(text):
    """é«˜å“è³ªå•†å“åã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼ˆæ—¢å­˜cleansing.pyæ©Ÿèƒ½çµ±åˆï¼‰"""
    if not text:
        return ""
    
    # Unicodeæ­£è¦åŒ–ï¼ˆNFKCï¼‰- æ—¢å­˜cleansing.pyæ©Ÿèƒ½
    text = unicodedata.normalize('NFKC', text)
    
    # é™¤å»å¯¾è±¡ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ—¢å­˜ã®é«˜å“è³ªæ©Ÿèƒ½ã‚’çµ±åˆï¼‰
    remove_patterns = [
        # çµµæ–‡å­—ãƒ»è¨˜å·
        r'[ğŸ…¹ğŸ…¿ğŸ‡¯ğŸ‡µâ˜…â˜†â€»â—â—‹â—â–²â–³â–¼â–½â– â–¡â—†â—‡â™¦â™¢â™ â™£â™¥â™¡]',
        r'[\u2600-\u26FF\u2700-\u27BF]',  # ãã®ä»–è¨˜å·
        
        # åœ¨åº«ãƒ»é…é€æƒ…å ±
        r'\[.*?stock.*?\]',
        r'\[.*?åœ¨åº«.*?\]',
        r'é€æ–™ç„¡æ–™',
        r'é…é€ç„¡æ–™',
        r'Free shipping',
        
        # å®£ä¼æ–‡å¥ãƒ»å“è³ªè¡¨ç¤º
        r'100% Authentic',
        r'made in japan',
        r'original',
        r'Direct from japan',
        r'Guaranteed authentic',
        r'æ­£è¦å“',
        r'æœ¬ç‰©',
        r'æ–°å“',
        r'æœªä½¿ç”¨',
        
        # è²©å£²è€…æƒ…å ±
        r'@.*',
        r'by.*store',
        r'shop.*',
        
        # å†—é•·ãªèª¬æ˜
        r'hair care liquid',
        r'beauty product',
        r'cosmetic',
    ]
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³é™¤å»
    for pattern in remove_patterns:
        text = re.sub(pattern, '', text, flags=re.IGNORECASE)
    
    # åœ°åŸŸæƒ…å ±ã®é™¤å»ï¼ˆå…ˆé ­ã®ã¿ï¼‰
    text = re.sub(r'^(Japan|Global|Korean|China)\s+', '', text, flags=re.IGNORECASE)
    
    # è¤‡æ•°å•†å“ã®åˆ†é›¢ï¼ˆæœ€åˆã®å•†å“ã®ã¿æŠ½å‡ºï¼‰
    if '/' in text and len(text.split('/')) > 1:
        text = text.split('/')[0].strip()
    
    # ä½™åˆ†ãªç©ºç™½ãƒ»è¨˜å·ã®é™¤å»
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'^[^\w\s]*|[^\w\s]*$', '', text)
    
    return text

def extract_brand_and_quantity(text, brand_dict):
    """é«˜å“è³ªãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»æ•°é‡æŠ½å‡ºï¼ˆextractors1.txtæ©Ÿèƒ½çµ±åˆï¼‰"""
    if not text:
        return {"brand": None, "quantity": None, "cleaned_text": text}
    
    # å•†å“åã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
    cleaned_text = advanced_product_name_cleansing(text)
    
    # ãƒ–ãƒ©ãƒ³ãƒ‰æŠ½å‡ºï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰
    detected_brand = None
    max_priority = 0
    
    for brand, variations in brand_dict.items():
        # variations ãŒæ–‡å­—åˆ—ã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
        if isinstance(variations, str):
            variations = [variations]
        elif not isinstance(variations, list):
            variations = []
        
        # brandã¨variationsã‚’çµ±åˆã—ã¦ãƒã‚§ãƒƒã‚¯
        all_variations = variations + [brand]
        
        for variation in all_variations:
            if not variation or not isinstance(variation, str):
                continue
                
            # å„ªå…ˆé †ä½ï¼ˆã‚«ã‚¿ã‚«ãƒŠ>æ¼¢å­—>ã²ã‚‰ãŒãª>è‹±å­—ï¼‰
            if re.search(r'[\u30A0-\u30FF]', variation):  # ã‚«ã‚¿ã‚«ãƒŠ
                priority = 4
            elif re.search(r'[\u4E00-\u9FFF]', variation):  # æ¼¢å­—
                priority = 3
            elif re.search(r'[\u3040-\u309F]', variation):  # ã²ã‚‰ãŒãª
                priority = 2
            else:  # è‹±å­—
                priority = 1
            
            # ãƒ–ãƒ©ãƒ³ãƒ‰åã®æ¤œå‡º
            try:
                if re.search(rf'\b{re.escape(variation)}\b', cleaned_text, re.IGNORECASE):
                    if priority > max_priority:
                        detected_brand = brand
                        max_priority = priority
            except Exception as e:
                print(f"âš ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰æ¤œç´¢ã‚¨ãƒ©ãƒ¼ (variation: {variation}): {e}")
                continue
    
    # æ•°é‡æŠ½å‡º
    quantity_pattern = r'(\d+(?:\.\d+)?)\s*(ml|g|kg|oz|L|â„“|cc|å€‹|æœ¬|æš|éŒ |ç²’|åŒ…|è¢‹)'
    quantity_match = re.search(quantity_pattern, cleaned_text, re.IGNORECASE)
    extracted_quantity = quantity_match.group() if quantity_match else None
    
    return {
        "brand": detected_brand,
        "quantity": extracted_quantity,
        "cleaned_text": cleaned_text
    }

def create_safe_fallback_step4(asin, error_reason, brand_name=None):
    """
    Primeåˆ¤å®šå¤±æ•—æ™‚ã®å®‰å…¨ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæƒ…å ±ã‚’è¿”ã™ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—C/unknownã§çµ±ä¸€, brand_nameã‚‚ä»˜ä¸ï¼‰
    """
    return {
        "asin": asin,
        "is_prime": False,
        "is_national_prime": False,
        "seller_name": "Unknown",
        "seller_id": "",
        "seller_type": "unknown",
        "is_amazon_seller": False,
        "is_official_seller": False,
        "category": "C",
        "prime_status": "NotPrime",
        "api_source": "ProductPricing_Fixed",
        "brand_used": brand_name,
        "error_reason": error_reason
    }

# ======================== Prime+å‡ºå“è€…æƒ…å ±æ©Ÿèƒ½ï¼ˆæ–°è¦è¿½åŠ ï¼‰ ========================

# sp_api_service.py - Primeæƒ…å ±å–å¾—ä¿®æ­£ç‰ˆï¼ˆè©²å½“é–¢æ•°ã®ã¿ï¼‰

def check_official_manufacturer_simple(seller_name: str, brand: str) -> bool:
    """
    seller_name ãŒå…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼ã‹ã©ã†ã‹ã‚’ç°¡æ˜“æ¨å®š
    - brand ã¨ seller_name ãŒ Jaro-Winkler > 0.9
    - seller_name ãŒ 'official'ãƒ»'å…¬å¼'ãƒ»'ç›´å–¶'ãƒ»'_jp' ã§çµ‚ã‚ã‚‹
    - WHITELIST_OFFICIAL_IDS ã«å«ã¾ã‚Œã‚‹
    """
    import jellyfish, re
    WHITELIST_OFFICIAL_IDS = {"A1234567890ABCDE", "B0987654321XYZ"}
    if seller_name in WHITELIST_OFFICIAL_IDS:
        return True
    if brand and jellyfish.jaro_winkler_similarity(brand.lower(), seller_name.lower()) > 0.9:
        return True
    return bool(re.search(r"(official|å…¬å¼|ç›´å–¶|_jp)$", seller_name.lower()))

def get_prime_and_seller_info(asin: str, credentials: dict, brand_name: str = "") -> dict:
    """
    æœ€çµ‚ä¿®æ­£ç‰ˆï¼šæ­£ã—ã„item_conditionãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä½¿ç”¨
    """
    print(f"ğŸ” get_prime_and_seller_infoé–‹å§‹: {asin}")
    
    try:
        from sp_api.base import SellingApiException
        
        # ProductPricingã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆï¼ˆ2023å¹´10æœˆä»¥é™AWSèªè¨¼ä¸è¦ï¼‰
        pp = ProductPricing(
            credentials=credentials, 
            marketplace=Marketplaces.JP
        )
        print(f"   âœ… ProductPricingã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆæˆåŠŸï¼ˆLWAèªè¨¼ã®ã¿ï¼‰")
        
        # æ­£ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åã§å‘¼ã³å‡ºã—
        print(f"   ğŸ“ get_item_offerså‘¼ã³å‡ºã—: {asin}")
        
        # ãƒ†ã‚¹ãƒˆçµæœã«åŸºã¥ãæ­£ã—ã„å‘¼ã³å‡ºã—
        offers_response = pp.get_item_offers(
            asin=asin,
            item_condition="New"  # æ­£ã—ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åï¼ˆå°æ–‡å­—ï¼‰
        )
        
        print(f"   âœ… get_item_offerså‘¼ã³å‡ºã—æˆåŠŸ")
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
        offers = offers_response.payload.get("Offers", [])
        print(f"   ğŸ“Š ã‚ªãƒ•ã‚¡ãƒ¼æ•°: {len(offers)}")
        
        if not offers:
            print(f"   âš ï¸ {asin}: ã‚ªãƒ•ã‚¡ãƒ¼æƒ…å ±ãªã—")
            return create_safe_fallback_step4(asin, "ã‚ªãƒ•ã‚¡ãƒ¼æƒ…å ±ãªã—", brand_name)

        # ãƒ‡ãƒãƒƒã‚°: offers[0]ã®æ§‹é€ ã‚’è¡¨ç¤º
        import json
        print(f"   ğŸ” ãƒ‡ãƒãƒƒã‚°: offers[0]ã®æ§‹é€ :")
        print(json.dumps(offers[0], indent=2, ensure_ascii=False))
        
        # Primeæƒ…å ±æŠ½å‡º
        top_offer = offers[0]
        prime_info = top_offer.get("PrimeInformation", {})
        is_prime = prime_info.get("IsPrime", False)
        is_national_prime = prime_info.get("IsNationalPrime", False)
        
        print(f"   ğŸ¯ Primeåˆ¤å®š: IsPrime={is_prime}, IsNationalPrime={is_national_prime}")
        
        # å‡ºå“è€…æƒ…å ±æŠ½å‡º
        seller_id = offers[0].get("SellerId", "")
        seller_name = offers[0].get("Name", "Unknown")
        
        print(f"   ğŸ‘¤ å‡ºå“è€…: ID={seller_id}, Name={seller_name}")
        
        # Amazonæœ¬ä½“åˆ¤å®š
        AMAZON_JP_SELLER_ID = 'A1VC38T7YXB528'
        is_amazon_seller = (seller_id == AMAZON_JP_SELLER_ID)
        
        # å…¬å¼ãƒ¡ãƒ¼ã‚«ãƒ¼åˆ¤å®š
        is_official_seller_flag = is_official_seller(seller_id, seller_name, brand_name)
        
        # A/B/Cåˆ†é¡
        if not is_prime:
            category = "C"
        elif is_amazon_seller or is_official_seller_flag:
            category = "A"
        else:
            category = "B"
        
        # ã‚»ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—æ±ºå®š
        if is_amazon_seller:
            seller_type = 'amazon'
        elif is_official_seller_flag:
            seller_type = 'official_manufacturer'
        else:
            seller_type = 'third_party'
        
        result = {
            "asin": asin,
            "is_prime": is_prime,
            "is_national_prime": is_national_prime,
            "seller_name": seller_name,
            "seller_id": seller_id,
            "seller_type": seller_type,
            "is_amazon_seller": is_amazon_seller,
            "is_official_seller": is_official_seller_flag,
            "category": category,
            "prime_status": "Prime" if is_prime else "NotPrime",
            "api_source": "ProductPricing_Fixed_Final",
            "brand_used": brand_name
        }
        
        print(f"   âœ… {asin}å®Œäº†: Prime={is_prime}, Category={category}, Seller={seller_type}")
        return result
        
    except SellingApiException as exc:
        print(f"   âŒ SP-API SellingApiExceptionè©³ç´°:")
        print(f"      Code: {exc.code}")
        payload = getattr(exc, "payload", None)
        print(f"      Payload: {payload}")
        print(f"      Headers: {getattr(exc, 'headers', 'N/A')}")
        
        # ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰åˆ¥å¯¾å‡¦æ³•ï¼ˆ2023å¹´10æœˆä»¥é™å¯¾å¿œï¼‰
        if exc.code == 401:
            print(f"      ğŸ”§ LWAèªè¨¼ã‚¨ãƒ©ãƒ¼: LWA_APP_ID/SECRET/TOKENã‚’ç¢ºèª")
        elif exc.code == 403:
            print(f"      ğŸ”§ æ¨©é™ã‚¨ãƒ©ãƒ¼: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ­ãƒ¼ãƒ«/æ¨©é™ã‚’ç¢ºèª")
        elif exc.code == 429:
            print(f"      ğŸ”§ ãƒ¬ãƒ¼ãƒˆåˆ¶é™: é–“éš”ã‚’ç©ºã‘ã¦ãƒªãƒˆãƒ©ã‚¤ï¼ˆ0.5RPSåˆ¶é™ï¼‰")
        elif exc.code == 404:
            print(f"      ğŸ”§ å•†å“æœªç™ºè¦‹: ASIN {asin} ãŒå­˜åœ¨ã—ãªã„ã‹å‰Šé™¤æ¸ˆã¿")
        
        return create_safe_fallback_step4(asin, f"SP-API-{exc.code}: {str(payload)[:100]}", brand_name)
        
    except Exception as exc:
        print(f"   âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {exc}")
        return create_safe_fallback_step4(asin, str(exc)[:60], brand_name)

def search_asin_with_enhanced_prime_seller(title, max_results=5):
    """
    Prime+å‡ºå“è€…æƒ…å ±çµ±åˆç‰ˆASINæ¤œç´¢ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    """
    credentials = get_credentials()
    if not credentials:
        return {
            'search_status': 'auth_error',
            'asin': '',
            'amazon_asin': '',
            'error_message': 'èªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“'
        }
    
    print(f"ğŸ” Prime+å‡ºå“è€…æƒ…å ±çµ±åˆæ¤œç´¢: {title[:50]}...")
    
    # åŸºæœ¬ã®ASINæ¤œç´¢å®Ÿè¡Œ
    basic_result = search_asin_with_prime_priority(title, max_results)
    
    if basic_result.get("search_status") == "success":
        asin = basic_result.get('asin') or basic_result.get('amazon_asin')
        
        if asin:
            # Prime+å‡ºå“è€…æƒ…å ±ã‚’è¿½åŠ å–å¾—
            print(f"   ğŸ“Š Prime+å‡ºå“è€…è©³ç´°åˆ†æ: {asin}")
            prime_seller_info = get_prime_and_seller_info(asin, credentials)
            
            # çµæœçµ±åˆ
            basic_result.update(prime_seller_info)
            
            # Shopeeå‡ºå“é©æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
            shopee_score = calculate_shopee_suitability_score(basic_result)
            basic_result['shopee_suitability_score'] = shopee_score
            
            # æœ€çµ‚ã‚°ãƒ«ãƒ¼ãƒ—åˆ¤å®š
            shopee_group = determine_shopee_group(basic_result)
            basic_result['shopee_group'] = shopee_group
            
            print(f"   âœ… Prime: {basic_result['is_prime']} | å‡ºå“è€…: {basic_result['seller_type']} | Shopeeé©æ€§: {shopee_score}ç‚¹ | ã‚°ãƒ«ãƒ¼ãƒ—: {shopee_group}")
    
    return basic_result

def process_batch_asin_search_with_ui(df, title_column='clean_title', limit=None):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ UIä»˜ããƒãƒƒãƒASINæ¤œç´¢ï¼ˆæ—¢å­˜æ©Ÿèƒ½å®Œå…¨çµ±åˆç‰ˆï¼‰"""
    # å‡¦ç†å¯¾è±¡ã®æ±ºå®š
    if limit:
        df_to_process = df.head(limit).copy()
    else:
        df_to_process = df.copy()
    
    total_items = len(df_to_process)
    
    print(f"ğŸš€ æ—¢å­˜æ©Ÿèƒ½çµ±åˆç‰ˆãƒãƒƒãƒASINæ¤œç´¢é–‹å§‹: {total_items}ä»¶ã®å•†å“ã‚’å‡¦ç†")
    print(f"ğŸ“Š çµ±åˆæ©Ÿèƒ½:")
    print(f"   âœ… é«˜å“è³ªå•†å“åã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°")
    print(f"   âœ… 500+ãƒ–ãƒ©ãƒ³ãƒ‰è¾æ›¸æ´»ç”¨")
    print(f"   âœ… æ”¹è‰¯ã•ã‚ŒãŸä¸€è‡´åº¦è¨ˆç®—")
    print(f"   âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤º")
    
    # UIè¦ç´ ã®åˆæœŸåŒ–
    progress_bar = st.progress(0)
    status_container = st.container()
    metrics_container = st.container()
    current_item_container = st.container()
    log_container = st.container()
    
    # çµæœã‚«ãƒ©ãƒ ã®åˆæœŸåŒ–
    result_columns = [
        'amazon_asin', 'amazon_title', 'amazon_brand', 'relevance_score',
        'is_prime', 'price', 'search_status', 'extracted_brand', 
        'extracted_quantity', 'cleaned_title', 'relevance_details',
        'japanese_name', 'llm_source'  # æ—¥æœ¬èªåŒ–æƒ…å ±ã‚’è¿½åŠ 
    ]
    
    for col in result_columns:
        if col not in df_to_process.columns:
            df_to_process[col] = ""
    
    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    success_count = 0
    error_count = 0
    detailed_logs = []
    
    for idx, row in df_to_process.iterrows():
        current_progress = (idx + 1) / total_items
        progress_bar.progress(current_progress)
        
        # ç¾åœ¨ã®å‡¦ç†çŠ¶æ³è¡¨ç¤º
        with current_item_container:
            st.write(f"ğŸ” {idx + 1}/{total_items}: æ¤œç´¢ä¸­")
            current_title = str(row[title_column])[:100] + ("..." if len(str(row[title_column])) > 100 else "")
            st.write(f"å•†å“å: {current_title}")
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
        with metrics_container:
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("å‡¦ç†æ¸ˆã¿", f"{idx + 1}/{total_items}")
            with col2:
                st.metric("æˆåŠŸ", f"{success_count}")
            with col3:
                st.metric("å¤±æ•—", f"{error_count}")
            with col4:
                success_rate = (success_count / (idx + 1)) * 100 if idx >= 0 else 0
                st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
        
        # ASINæ¤œç´¢å®Ÿè¡Œ
        search_result = search_asin_with_prime_priority(str(row[title_column]))
        
        # çµæœã®å‡¦ç†
        if search_result.get("search_status") == "success":
            success_count += 1
            df_to_process.at[idx, 'amazon_asin'] = search_result['asin']
            df_to_process.at[idx, 'amazon_title'] = search_result['amazon_title']
            df_to_process.at[idx, 'amazon_brand'] = search_result.get('amazon_brand', '')
            df_to_process.at[idx, 'relevance_score'] = search_result['relevance_score']
            df_to_process.at[idx, 'is_prime'] = search_result.get('is_prime', False)
            df_to_process.at[idx, 'price'] = search_result.get('price', '')
            df_to_process.at[idx, 'search_status'] = search_result['search_status']
            
            # ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»æ•°é‡æŠ½å‡ºçµæœã‚’çµ±åˆ
            brand_info = extract_brand_and_quantity(search_result.get('amazon_title', ''), load_brand_dict())
            df_to_process.at[idx, 'extracted_brand'] = brand_info['brand'] or ''
            df_to_process.at[idx, 'extracted_quantity'] = brand_info['quantity'] or ''
            df_to_process.at[idx, 'cleaned_title'] = brand_info['cleaned_text'] or ''
            
            # æ—¥æœ¬èªåŒ–å‡¦ç†
            if df_to_process.at[idx, 'cleaned_title']:
                japanese_name, llm_source = get_japanese_name_hybrid(df_to_process.at[idx, 'cleaned_title'])
                df_to_process.at[idx, 'japanese_name'] = japanese_name
                df_to_process.at[idx, 'llm_source'] = llm_source
            
            # è©³ç´°ãƒ­ã‚°
            detailed_logs.append(f"æˆåŠŸ: {search_result['asin']} - ãƒ–ãƒ©ãƒ³ãƒ‰: {df_to_process.at[idx, 'extracted_brand']} - ã‚¿ã‚¤ãƒˆãƒ«: {df_to_process.at[idx, 'cleaned_title']}")
        else:
            error_count += 1
            df_to_process.at[idx, 'search_status'] = search_result.get('error_message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')
            detailed_logs.append(f"å¤±æ•—: {search_result.get('error_message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
        
        # ç¾åœ¨ã®è©³ç´°ãƒ­ã‚°è¡¨ç¤º
        with log_container:
            st.write("è©³ç´°ãƒ­ã‚°:")
            for log in detailed_logs[-10:]:  # æœ€æ–°ã®10ä»¶ã‚’è¡¨ç¤º
                st.write(f"- {log}")
    
    # æœ€çµ‚çµæœã®è¡¨ç¤º
    st.write(f"âœ… ãƒãƒƒãƒå‡¦ç†å®Œäº†: {success_count}ä»¶æˆåŠŸ, {error_count}ä»¶å¤±æ•—")
    
    return df_to_process

def search_asin_with_prime_priority(title, max_results=5):
    """
    ãƒ€ãƒŸãƒ¼: Primeå„ªå…ˆASINæ¤œç´¢ï¼ˆå¾ªç’°å‚ç…§é˜²æ­¢ã®ãŸã‚å†å¸°å‘¼ã³å‡ºã—ãªã—ï¼‰
    """
    # æœ¬ç•ªã§ã¯å®Ÿè£…ã‚’å·®ã—æ›¿ãˆ
    return {
        'search_status': 'not_implemented',
        'asin': '',
        'amazon_asin': '',
        'error_message': 'search_asin_with_prime_priorityã¯ãƒ€ãƒŸãƒ¼ã§ã™'
    }

def calculate_shopee_suitability_score(product_info):
    """
    ãƒ€ãƒŸãƒ¼: Shopeeé©æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆæœ¬ç•ªã§ã¯asin_helpersç­‰ã§å®Ÿè£…ï¼‰
    """
    return 80

def determine_shopee_group(product_info):
    """
    ãƒ€ãƒŸãƒ¼: Shopeeã‚°ãƒ«ãƒ¼ãƒ—åˆ¤å®šï¼ˆA/B/Cï¼‰
    """
    return product_info.get('category', 'C')