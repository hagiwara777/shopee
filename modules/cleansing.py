# modules/cleansing.py (ä¿®æ­£ç‰ˆ - ç‰¹å®šã®çµµæ–‡å­—å‰Šé™¤ã‚’è¿½åŠ )

import unicodedata
import re
from pathlib import Path

# dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’å–å¾— (ä¿®æ­£)
# __file__ ã¯ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«(cleansing.py)ã®ãƒ‘ã‚¹
# .resolve() ã§çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
# .parents[1] ã§ä¸€ã¤ä¸Šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (modules/ ã®è¦ª = ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ)
# ãã“ã‹ã‚‰ "data" ãƒ•ã‚©ãƒ«ãƒ€ã‚’çµåˆ
DATA_DIR = Path(__file__).resolve().parents[1] / "data"

def normalize(text: str) -> str:
    """
    æ–‡å­—åˆ—ã‚’æ­£è¦åŒ–ã—ã€ä¸è¦ãªæ–‡å­—ã‚„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å‰Šé™¤ã™ã‚‹é–¢æ•°ã€‚
    NFKCæ­£è¦åŒ–ã€å°æ–‡å­—åŒ–ã€æ‹¬å¼§ãƒ»ç‰¹å®šè¨˜å·ãƒ»çµµæ–‡å­—ã®é™¤å»ã€
    ignore_phrases.txt ã«è¨˜è¼‰ã•ã‚ŒãŸãƒ•ãƒ¬ãƒ¼ã‚ºã®é™¤å»ã‚’è¡Œã†ã€‚
    """
    if not isinstance(text, str):
        return "" # æ–‡å­—åˆ—ã§ãªã„å ´åˆã¯ç©ºæ–‡å­—ã‚’è¿”ã™

    # NFKCæ­£è¦åŒ–ã¨å°æ–‡å­—åŒ–
    try:
        # unicodedata.normalize ã¯ str ã®ã¿å—ã‘ä»˜ã‘ã‚‹
        text_normalized = unicodedata.normalize("NFKC", str(text)).lower()
    except TypeError:
        # ä¸‡ãŒä¸€ã€str() ã«å¤‰æ›ã§ããªã„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒæ¥ãŸå ´åˆï¼ˆé€šå¸¸ã¯ã‚ã‚Šãˆãªã„ãŒï¼‰
        return ""

    # --- ã“ã“ã‹ã‚‰æ–‡å­—å‰Šé™¤å‡¦ç† ---

    # 1. æ‹¬å¼§ãƒ»è¨˜å·é¡ã®é™¤å»ï¼ˆä¾‹ï¼š[], (), ã€ã€‘ï¼‰
    text_cleaned = re.sub(r"[\[\]ã€ã€‘()ï¼ˆï¼‰]", "", text_normalized)

    # 2. ç‰¹å®šã®è¨˜å·ã‚„çµµæ–‡å­—ã®é™¤å»ï¼ˆæŒ‡å®šã•ã‚ŒãŸ âœ¨ğŸ”¥ğŸ‘ğŸ‰ ã¨ã€å‰å›å®šç¾©ã—ãŸ ğŸ…¹ğŸ…¿ğŸ‡¯ğŸ‡µï¼‰
    #    å‰Šé™¤ã—ãŸã„æ–‡å­—ã‚’ [] ã®ä¸­ã«è¿½åŠ ã—ã¦ã„ã
    specific_chars_to_remove = r"[âœ¨ğŸ”¥ğŸ‘ğŸ‰ğŸ…¹ğŸ…¿ğŸ‡¯ğŸ‡µ]"
    text_cleaned = re.sub(specific_chars_to_remove, "", text_cleaned, flags=re.UNICODE)

    # 3. ç„¡è¦–ãƒªã‚¹ãƒˆ (ignore_phrases.txt) ã®é™¤å»
    ignore_path = DATA_DIR / "ignore_phrases.txt" # æ­£ã—ã„ãƒ‘ã‚¹ã‚’ä½¿ç”¨
    if ignore_path.exists():
        try:
            # ã¾ãšUTF-8ã§è©¦ã™
            ignore_phrases = ignore_path.read_text(encoding="utf-8").splitlines()
        except UnicodeDecodeError:
            try:
                # Shift-JISã§è©¦ã™
                print(f"è­¦å‘Š: {ignore_path} ã®UTF-8èª­ã¿è¾¼ã¿å¤±æ•—ã€‚Shift-JISã§è©¦è¡Œã—ã¾ã™ã€‚")
                ignore_phrases = ignore_path.read_text(encoding="shift_jis").splitlines()
            except Exception as read_e:
                print(f"è­¦å‘Š: {ignore_path} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {read_e}")
                ignore_phrases = [] # èª­ã¿è¾¼ã‚ãªã„å ´åˆã¯ãƒªã‚¹ãƒˆã‚’ç©ºã«ã™ã‚‹
        except Exception as e:
             print(f"è­¦å‘Š: {ignore_path} ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
             ignore_phrases = []

        # ãƒ•ãƒ¬ãƒ¼ã‚ºé™¤å»å‡¦ç†
        for phrase in ignore_phrases:
            phrase_clean = phrase.strip()
            if phrase_clean: # ç©ºè¡Œã¯ç„¡è¦–
                try:
                    # re.escapeã§æ­£è¦è¡¨ç¾ã®ç‰¹æ®Šæ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã€IGNORECASEã§å¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–
                    text_cleaned = re.sub(re.escape(phrase_clean.lower()), "", text_cleaned, flags=re.IGNORECASE)
                except re.error as re_err:
                    print(f"è­¦å‘Š: ignore_phrases.txt å†…ã®ãƒ•ãƒ¬ãƒ¼ã‚º '{phrase_clean}' ã®æ­£è¦è¡¨ç¾å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {re_err}ã€‚å˜ç´”ç½®æ›ã‚’è©¦ã¿ã¾ã™ã€‚")
                    # æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€å˜ç´”ãªæ–‡å­—åˆ—ç½®æ›ã§è©¦ã¿ã‚‹ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ç„¡è¦–ã¯ã§ããªã„ï¼‰
                    text_cleaned = text_cleaned.replace(phrase_clean.lower(), "")
    else:
        print(f"è­¦å‘Š: {ignore_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ•ãƒ¬ãƒ¼ã‚ºé™¤å»ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")


    # 4. æœ€å¾Œã«å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    return text_cleaned.strip()